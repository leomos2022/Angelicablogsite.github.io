{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeuXej005w4U4r/ACkCXIg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomos2022/Angelicablogsite.github.io/blob/main/Copy_of_Perceptron_Multicapa_S2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdinIv-TRDug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<div style=\"text-align: center; font-family: Arial, sans-serif;\">\n",
        "\n",
        "  <!-- Título principal centrado y grande -->\n",
        "  <h1 style=\"font-size: 48px; font-weight: bold; margin-bottom: 5px;\">📘 Práctica Individual</h1>\n",
        "\n",
        "  <!-- Subtítulo centrado -->\n",
        "  <h2 style=\"font-size: 36px; font-weight: bold; margin-top: 0; margin-bottom: 20px;\">Evaluación de Perceptrón Multicapa</h2>\n",
        "\n",
        "  <!-- Información del estudiante -->\n",
        "  <p style=\"font-size: 24px; font-weight: bold; margin-top: 10px;\">\n",
        "    Estudiante: Leonardo Mosquera<br>\n",
        "    Fecha: 12/09/2025\n",
        "  </p>\n",
        "\n",
        "  <!-- Objetivo -->\n",
        "  <p style=\"font-size: 22px; font-weight: bold; margin-top: 30px;\">🔍 Objetivo</p>\n",
        "  <p style=\"font-size: 20px; text-align: justify; margin-left: 20%; margin-right: 20%;\">\n",
        "    Verificar el desempeño de los algoritmos de redes neuronales (específicamente el Perceptrón Multicapa) mediante métricas de evaluación apropiadas.\n",
        "  </p>\n",
        "\n",
        "</div>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X6Fq-di_C_-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "# URL de la imagen\n",
        "imagen_url = \"https://blog.josemarianoalvarez.com/wp-content/uploads/2018/06/ModeloPerceptron-768x444.jpeg\"  # Reemplaza con la URL real\n",
        "\n",
        "# Tamaño de la imagen en pixeles (ancho)\n",
        "ancho = 800\n",
        "\n",
        "# Título debajo de la imagen\n",
        "titulo = \"Figura 1. Perceptrón Multicapa\"\n",
        "\n",
        "# Mostrar imagen centrada con título\n",
        "display(HTML(f'''\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"{imagen_url}\" width=\"{ancho}\">\n",
        "    <p style=\"font-weight: bold;\">{titulo}</p>\n",
        "</div>\n",
        "'''))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "K_xHfAwFBVyu",
        "outputId": "54934d61-0843-4a40-cc90-a0da31a17a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"text-align: center;\">\n",
              "    <img src=\"https://blog.josemarianoalvarez.com/wp-content/uploads/2018/06/ModeloPerceptron-768x444.jpeg\" width=\"800\">\n",
              "    <p style=\"font-weight: bold;\">Figura 1. Perceptrón Multicapa</p>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📦 1. Importación de Librerías\n",
        "En esta sección se importan las librerías necesarias para generar datos simulados, procesarlos, construir y evaluar el modelo Perceptrón Multicapa (MLP).\n"
      ],
      "metadata": {
        "id": "3sOMPaMfEjK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n"
      ],
      "metadata": {
        "id": "eMrVMFDLCWP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧪 2. Generación del Dataset\n",
        "Se crea un conjunto de datos sintético para simular un problema de clasificación binaria.  \n",
        "Luego se divide en entrenamiento y prueba, y se escalan los datos para mejorar el rendimiento del modelo.\n"
      ],
      "metadata": {
        "id": "hQEnBzHwE7ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=12,\n",
        "    n_informative=8,\n",
        "    n_redundant=2,\n",
        "    n_classes=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# División en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalado de datos\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "GxU1ejqtEVp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧠 3. Implementación del Perceptrón Multicapa\n",
        "Aquí se construye y entrena el modelo utilizando **MLPClassifier** de *scikit-learn*.  \n",
        "La red tiene dos capas ocultas (16 y 8 neuronas) con función de activación **ReLU**.\n"
      ],
      "metadata": {
        "id": "PLAsrBlwFRFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(16, 8),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=300,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred = mlp.predict(X_test_scaled)\n",
        "y_proba = mlp.predict_proba(X_test_scaled)[:, 1]\n"
      ],
      "metadata": {
        "id": "7zsOtqcCEdSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JDUANylTFZKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📈 4. Evaluación del Modelo\n",
        "Se presentan las métricas de evaluación que permiten analizar el rendimiento del modelo:\n",
        "- **Accuracy**  \n",
        "- **ROC AUC**  \n",
        "- **Matriz de confusión**  \n",
        "- **Reporte de clasificación (precision, recall, f1-score)**\n"
      ],
      "metadata": {
        "id": "zadmPUlmFnNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📈 4. Evaluación del Modelo\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"\\nMatriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nReporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "e76oleuHFoIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3v9okboPFt7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 5. Reflexión y Análisis  \n",
        "\n",
        "**1. ¿En qué consiste el desempeño de un algoritmo de red neuronal como el Perceptrón Multicapa?**  \n",
        "El desempeño consiste en la capacidad del Perceptrón Multicapa para aprender patrones complejos en los datos y generalizar ese conocimiento para predecir nuevas muestras. A diferencia del perceptrón simple, este puede resolver problemas no lineales gracias a sus capas ocultas y funciones de activación.  \n",
        "\n",
        "**2. ¿Cuáles son las métricas más importantes para evaluar su desempeño en clasificación binaria?**  \n",
        "Las métricas más relevantes son la **accuracy** (qué tan bien clasifica en general), la **precisión** (confiabilidad de las predicciones positivas), el **recall** (capacidad de identificar los casos positivos), el **F1-score** (equilibrio entre precisión y recall) y el **ROC AUC** (capacidad de distinguir entre clases bajo diferentes umbrales).  \n",
        "\n",
        "**3. ¿Qué significa una buena puntuación en ROC AUC? ¿Es mejor que la accuracy?**  \n",
        "Una puntuación alta en **ROC AUC** (cercana a 1) significa que el modelo diferencia bien entre clases positivas y negativas en distintos escenarios de decisión. Es más robusta que la accuracy cuando hay desbalance de clases, ya que esta última puede dar una impresión equivocada si una clase domina los datos.  \n",
        "\n",
        "**4. ¿Cómo influye el número de capas ocultas y neuronas en el desempeño del modelo?**  \n",
        "El número de capas y neuronas determina la complejidad del modelo. Pocas capas pueden limitar su capacidad de aprendizaje, mientras que demasiadas pueden causar sobreajuste y alto costo computacional. La clave está en encontrar un balance que permita al modelo aprender lo suficiente sin perder capacidad de generalización.  \n"
      ],
      "metadata": {
        "id": "dMvX3pihGuvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Perceptron\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "# Datos OR\n",
        "X_or = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y_or = np.array([0,1,1,1])  # salida OR\n",
        "\n",
        "# Entrenamos Perceptrón para OR\n",
        "clf_or = Perceptron(max_iter=1000, eta0=0.1, random_state=42)\n",
        "clf_or.fit(X_or, y_or)\n",
        "\n",
        "# Visualizamos frontera de decisión OR\n",
        "plt.figure(figsize=(6,4))\n",
        "plot_decision_regions(X_or, y_or, clf_or)\n",
        "plt.title(\"Frontera de decisión - OR con Perceptrón\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()\n",
        "\n",
        "# Datos XOR\n",
        "y_xor = np.array([0,1,1,0])  # salida XOR\n",
        "\n",
        "# Entrenamos Perceptrón para XOR\n",
        "clf_xor = Perceptron(max_iter=1000, eta0=0.1, random_state=42)\n",
        "clf_xor.fit(X_or, y_xor)\n",
        "\n",
        "# Visualizamos frontera de decisión XOR\n",
        "plt.figure(figsize=(6,4))\n",
        "plot_decision_regions(X_or, y_xor, clf_xor)\n",
        "plt.title(\"Frontera de decisión - XOR con Perceptrón\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eJ_F9quJGwG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXxYOkpzHBc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Conclusiones Finales\n",
        "\n",
        "1. **El Perceptrón simple** es capaz de resolver problemas linealmente separables como el **OR**, pero fracasa en casos no lineales como el **XOR**.  \n",
        "\n",
        "2. Esto demuestra la **limitación de los modelos lineales** y la necesidad de estructuras más complejas como el **Perceptrón Multicapa (MLP)** para capturar relaciones no lineales.  \n",
        "\n",
        "3. El uso de **métricas de evaluación** (Accuracy, ROC AUC, matriz de confusión, F1-score) permite valorar de manera integral el rendimiento del modelo, más allá de un único número.  \n",
        "\n",
        "4. La métrica **ROC AUC** es especialmente útil en problemas de clasificación binaria desbalanceados, ya que mide la capacidad del modelo para distinguir entre clases en diferentes umbrales.  \n",
        "\n",
        "5. El **número de capas y neuronas ocultas** influye directamente en la capacidad del modelo: más capas aumentan su poder de representación, pero también el riesgo de sobreajuste y mayor costo computacional.  \n",
        "\n",
        "6. En conclusión, los **modelos neuronales avanzados** como los MLP permiten resolver problemas que los perceptrones simples no pueden, mostrando el avance de la inteligencia artificial en tareas complejas de clasificación.  \n"
      ],
      "metadata": {
        "id": "LnLxjxNCHTEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📚 Referencias\n",
        "\n",
        "- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.  \n",
        "\n",
        "- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.  \n",
        "\n",
        "- Haykin, S. (2009). *Neural Networks and Learning Machines* (3rd ed.). Pearson.  \n",
        "\n",
        "- Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... & Duchesnay, É. (2011). Scikit-learn: Machine Learning in Python. *Journal of Machine Learning Research*, 12, 2825–2830.  \n",
        "\n",
        "- Shalev-Shwartz, S., & Ben-David, S. (2014). *Understanding Machine Learning: From Theory to Algorithms*. Cambridge University Press.  \n"
      ],
      "metadata": {
        "id": "nVxPkEJJHZlv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yz89FUqHT1T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}