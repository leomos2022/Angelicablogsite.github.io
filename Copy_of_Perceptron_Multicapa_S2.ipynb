{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeuXej005w4U4r/ACkCXIg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomos2022/Angelicablogsite.github.io/blob/main/Copy_of_Perceptron_Multicapa_S2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdinIv-TRDug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<div style=\"text-align: center; font-family: Arial, sans-serif;\">\n",
        "\n",
        "  <!-- T√≠tulo principal centrado y grande -->\n",
        "  <h1 style=\"font-size: 48px; font-weight: bold; margin-bottom: 5px;\">üìò Pr√°ctica Individual</h1>\n",
        "\n",
        "  <!-- Subt√≠tulo centrado -->\n",
        "  <h2 style=\"font-size: 36px; font-weight: bold; margin-top: 0; margin-bottom: 20px;\">Evaluaci√≥n de Perceptr√≥n Multicapa</h2>\n",
        "\n",
        "  <!-- Informaci√≥n del estudiante -->\n",
        "  <p style=\"font-size: 24px; font-weight: bold; margin-top: 10px;\">\n",
        "    Estudiante: Leonardo Mosquera<br>\n",
        "    Fecha: 12/09/2025\n",
        "  </p>\n",
        "\n",
        "  <!-- Objetivo -->\n",
        "  <p style=\"font-size: 22px; font-weight: bold; margin-top: 30px;\">üîç Objetivo</p>\n",
        "  <p style=\"font-size: 20px; text-align: justify; margin-left: 20%; margin-right: 20%;\">\n",
        "    Verificar el desempe√±o de los algoritmos de redes neuronales (espec√≠ficamente el Perceptr√≥n Multicapa) mediante m√©tricas de evaluaci√≥n apropiadas.\n",
        "  </p>\n",
        "\n",
        "</div>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X6Fq-di_C_-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "# URL de la imagen\n",
        "imagen_url = \"https://blog.josemarianoalvarez.com/wp-content/uploads/2018/06/ModeloPerceptron-768x444.jpeg\"  # Reemplaza con la URL real\n",
        "\n",
        "# Tama√±o de la imagen en pixeles (ancho)\n",
        "ancho = 800\n",
        "\n",
        "# T√≠tulo debajo de la imagen\n",
        "titulo = \"Figura 1. Perceptr√≥n Multicapa\"\n",
        "\n",
        "# Mostrar imagen centrada con t√≠tulo\n",
        "display(HTML(f'''\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"{imagen_url}\" width=\"{ancho}\">\n",
        "    <p style=\"font-weight: bold;\">{titulo}</p>\n",
        "</div>\n",
        "'''))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "K_xHfAwFBVyu",
        "outputId": "54934d61-0843-4a40-cc90-a0da31a17a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"text-align: center;\">\n",
              "    <img src=\"https://blog.josemarianoalvarez.com/wp-content/uploads/2018/06/ModeloPerceptron-768x444.jpeg\" width=\"800\">\n",
              "    <p style=\"font-weight: bold;\">Figura 1. Perceptr√≥n Multicapa</p>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ 1. Importaci√≥n de Librer√≠as\n",
        "En esta secci√≥n se importan las librer√≠as necesarias para generar datos simulados, procesarlos, construir y evaluar el modelo Perceptr√≥n Multicapa (MLP).\n"
      ],
      "metadata": {
        "id": "3sOMPaMfEjK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n"
      ],
      "metadata": {
        "id": "eMrVMFDLCWP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ 2. Generaci√≥n del Dataset\n",
        "Se crea un conjunto de datos sint√©tico para simular un problema de clasificaci√≥n binaria.  \n",
        "Luego se divide en entrenamiento y prueba, y se escalan los datos para mejorar el rendimiento del modelo.\n"
      ],
      "metadata": {
        "id": "hQEnBzHwE7ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=12,\n",
        "    n_informative=8,\n",
        "    n_redundant=2,\n",
        "    n_classes=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Divisi√≥n en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalado de datos\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "GxU1ejqtEVp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† 3. Implementaci√≥n del Perceptr√≥n Multicapa\n",
        "Aqu√≠ se construye y entrena el modelo utilizando **MLPClassifier** de *scikit-learn*.  \n",
        "La red tiene dos capas ocultas (16 y 8 neuronas) con funci√≥n de activaci√≥n **ReLU**.\n"
      ],
      "metadata": {
        "id": "PLAsrBlwFRFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(16, 8),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=300,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred = mlp.predict(X_test_scaled)\n",
        "y_proba = mlp.predict_proba(X_test_scaled)[:, 1]\n"
      ],
      "metadata": {
        "id": "7zsOtqcCEdSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JDUANylTFZKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìà 4. Evaluaci√≥n del Modelo\n",
        "Se presentan las m√©tricas de evaluaci√≥n que permiten analizar el rendimiento del modelo:\n",
        "- **Accuracy**  \n",
        "- **ROC AUC**  \n",
        "- **Matriz de confusi√≥n**  \n",
        "- **Reporte de clasificaci√≥n (precision, recall, f1-score)**\n"
      ],
      "metadata": {
        "id": "zadmPUlmFnNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìà 4. Evaluaci√≥n del Modelo\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"\\nMatriz de Confusi√≥n:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nReporte de Clasificaci√≥n:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "e76oleuHFoIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3v9okboPFt7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù 5. Reflexi√≥n y An√°lisis  \n",
        "\n",
        "**1. ¬øEn qu√© consiste el desempe√±o de un algoritmo de red neuronal como el Perceptr√≥n Multicapa?**  \n",
        "El desempe√±o consiste en la capacidad del Perceptr√≥n Multicapa para aprender patrones complejos en los datos y generalizar ese conocimiento para predecir nuevas muestras. A diferencia del perceptr√≥n simple, este puede resolver problemas no lineales gracias a sus capas ocultas y funciones de activaci√≥n.  \n",
        "\n",
        "**2. ¬øCu√°les son las m√©tricas m√°s importantes para evaluar su desempe√±o en clasificaci√≥n binaria?**  \n",
        "Las m√©tricas m√°s relevantes son la **accuracy** (qu√© tan bien clasifica en general), la **precisi√≥n** (confiabilidad de las predicciones positivas), el **recall** (capacidad de identificar los casos positivos), el **F1-score** (equilibrio entre precisi√≥n y recall) y el **ROC AUC** (capacidad de distinguir entre clases bajo diferentes umbrales).  \n",
        "\n",
        "**3. ¬øQu√© significa una buena puntuaci√≥n en ROC AUC? ¬øEs mejor que la accuracy?**  \n",
        "Una puntuaci√≥n alta en **ROC AUC** (cercana a 1) significa que el modelo diferencia bien entre clases positivas y negativas en distintos escenarios de decisi√≥n. Es m√°s robusta que la accuracy cuando hay desbalance de clases, ya que esta √∫ltima puede dar una impresi√≥n equivocada si una clase domina los datos.  \n",
        "\n",
        "**4. ¬øC√≥mo influye el n√∫mero de capas ocultas y neuronas en el desempe√±o del modelo?**  \n",
        "El n√∫mero de capas y neuronas determina la complejidad del modelo. Pocas capas pueden limitar su capacidad de aprendizaje, mientras que demasiadas pueden causar sobreajuste y alto costo computacional. La clave est√° en encontrar un balance que permita al modelo aprender lo suficiente sin perder capacidad de generalizaci√≥n.  \n"
      ],
      "metadata": {
        "id": "dMvX3pihGuvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Perceptron\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "# Datos OR\n",
        "X_or = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y_or = np.array([0,1,1,1])  # salida OR\n",
        "\n",
        "# Entrenamos Perceptr√≥n para OR\n",
        "clf_or = Perceptron(max_iter=1000, eta0=0.1, random_state=42)\n",
        "clf_or.fit(X_or, y_or)\n",
        "\n",
        "# Visualizamos frontera de decisi√≥n OR\n",
        "plt.figure(figsize=(6,4))\n",
        "plot_decision_regions(X_or, y_or, clf_or)\n",
        "plt.title(\"Frontera de decisi√≥n - OR con Perceptr√≥n\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()\n",
        "\n",
        "# Datos XOR\n",
        "y_xor = np.array([0,1,1,0])  # salida XOR\n",
        "\n",
        "# Entrenamos Perceptr√≥n para XOR\n",
        "clf_xor = Perceptron(max_iter=1000, eta0=0.1, random_state=42)\n",
        "clf_xor.fit(X_or, y_xor)\n",
        "\n",
        "# Visualizamos frontera de decisi√≥n XOR\n",
        "plt.figure(figsize=(6,4))\n",
        "plot_decision_regions(X_or, y_xor, clf_xor)\n",
        "plt.title(\"Frontera de decisi√≥n - XOR con Perceptr√≥n\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eJ_F9quJGwG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXxYOkpzHBc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Conclusiones Finales\n",
        "\n",
        "1. **El Perceptr√≥n simple** es capaz de resolver problemas linealmente separables como el **OR**, pero fracasa en casos no lineales como el **XOR**.  \n",
        "\n",
        "2. Esto demuestra la **limitaci√≥n de los modelos lineales** y la necesidad de estructuras m√°s complejas como el **Perceptr√≥n Multicapa (MLP)** para capturar relaciones no lineales.  \n",
        "\n",
        "3. El uso de **m√©tricas de evaluaci√≥n** (Accuracy, ROC AUC, matriz de confusi√≥n, F1-score) permite valorar de manera integral el rendimiento del modelo, m√°s all√° de un √∫nico n√∫mero.  \n",
        "\n",
        "4. La m√©trica **ROC AUC** es especialmente √∫til en problemas de clasificaci√≥n binaria desbalanceados, ya que mide la capacidad del modelo para distinguir entre clases en diferentes umbrales.  \n",
        "\n",
        "5. El **n√∫mero de capas y neuronas ocultas** influye directamente en la capacidad del modelo: m√°s capas aumentan su poder de representaci√≥n, pero tambi√©n el riesgo de sobreajuste y mayor costo computacional.  \n",
        "\n",
        "6. En conclusi√≥n, los **modelos neuronales avanzados** como los MLP permiten resolver problemas que los perceptrones simples no pueden, mostrando el avance de la inteligencia artificial en tareas complejas de clasificaci√≥n.  \n"
      ],
      "metadata": {
        "id": "LnLxjxNCHTEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Referencias\n",
        "\n",
        "- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.  \n",
        "\n",
        "- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.  \n",
        "\n",
        "- Haykin, S. (2009). *Neural Networks and Learning Machines* (3rd ed.). Pearson.  \n",
        "\n",
        "- Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... & Duchesnay, √â. (2011). Scikit-learn: Machine Learning in Python. *Journal of Machine Learning Research*, 12, 2825‚Äì2830.  \n",
        "\n",
        "- Shalev-Shwartz, S., & Ben-David, S. (2014). *Understanding Machine Learning: From Theory to Algorithms*. Cambridge University Press.  \n"
      ],
      "metadata": {
        "id": "nVxPkEJJHZlv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yz89FUqHT1T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}